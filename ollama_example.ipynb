{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b812173d",
   "metadata": {},
   "source": [
    "# Imports + Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3cd2fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing_extensions in /data/users2/agreene46/envs/pt2/lib/python3.10/site-packages (4.14.1)\n",
      "Requirement already satisfied: pydantic in /data/users2/agreene46/envs/pt2/lib/python3.10/site-packages (2.11.7)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /data/users2/agreene46/envs/pt2/lib/python3.10/site-packages (from pydantic) (2.33.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /data/users2/agreene46/envs/pt2/lib/python3.10/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /data/users2/agreene46/envs/pt2/lib/python3.10/site-packages (from pydantic) (0.4.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /data/users2/agreene46/envs/pt2/lib/python3.10/site-packages (from pydantic) (4.14.1)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "!pip install --upgrade typing_extensions\n",
    "!pip install pydantic\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "from typing import Union\n",
    "\n",
    "# Ollama Config\n",
    "OLLAMA_NODE = \"arctrdagn037\"\n",
    "BASE_URL = f\"http://{OLLAMA_NODE}:11434/api/chat\"\n",
    "\n",
    "model = \"gemma3-optimized:27b\" # qwq:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758f1de4",
   "metadata": {},
   "source": [
    "#  Grabbing DAIC-WOZ data (Data Loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f917ba",
   "metadata": {},
   "source": [
    "## Grabbing all participant IDs that have all the PHQ-8 questionare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a8194eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300, 301, 302, 306, 307, 308, 309, 311, 314, 323, 329, 331, 332, 334, 335, 337, 346, 349, 354, 359, 361, 365, 367, 373, 377, 378, 381, 382, 384, 387, 388, 389, 390, 395, 396, 399, 403, 404, 405, 406, 407, 408, 410, 411, 413, 417, 418, 420, 421, 422, 424, 431, 432, 435, 436, 438, 439, 440, 442, 450, 451, 452, 453, 458, 461, 462, 465, 466, 467, 469, 470, 472, 476, 477, 480, 481, 482, 483, 484, 489, 490, 492]\n"
     ]
    }
   ],
   "source": [
    "dev_split_phq8 = pd.read_csv(r\"/data/users4/xli/ai-psychiatrist/datasets/daic_woz_dataset/dev_split_Depression_AVEC2017.csv\")\n",
    "train_split_phq8 = pd.read_csv(r\"/data/users4/xli/ai-psychiatrist/datasets/daic_woz_dataset/full_test_split.csv\")\n",
    "\n",
    "participant_ids = set()\n",
    "\n",
    "# Grabbing unique participant ID values and putting them in a list\n",
    "\n",
    "participant_ids.update(dev_split_phq8['Participant_ID'])\n",
    "participant_ids.update(train_split_phq8['Participant_ID'])\n",
    "\n",
    "participant_list = sorted(list(participant_ids))\n",
    "print(participant_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee33cfb",
   "metadata": {},
   "source": [
    "## Quantitative Assesment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df5711a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Predicted vs Ground Truth:\n",
      "Metric\t\t\tPredicted\tGround Truth\tDifference\n",
      "-----------------------------------------------------------------\n",
      "PHQ8_NoInterest         1            0               1\n",
      "PHQ8_Depressed          1            1               0\n",
      "PHQ8_Sleep              3            1               2\n",
      "PHQ8_Tired              3            2               1\n",
      "PHQ8_Appetite           N/A          2               N/A\n",
      "PHQ8_Failure            N/A          1               N/A\n",
      "PHQ8_Concentrating      1            0               1\n",
      "PHQ8_Moving             0            0               0\n",
      "-----------------------------------------------------------------\n",
      "Average Absolute Difference (on available): 0.83\n",
      "Accuracy on available questions: 72.22%\n",
      "Questions marked N/A: 2/8\n",
      "Overall accuracy: 54.17%\n",
      "\n",
      "\n",
      "Detailed Reasoning for Each Score:\n",
      "================================================================================\n",
      "\n",
      "Little Interest/Pleasure (Score: 1)\n",
      "----------------------------------------\n",
      "Evidence: I don't like people. I don't like crowds. I enjoy being outdoors, painting, fishing, and driving.\n",
      "Reason: Mixed evidence of enjoyment and aversion. No clear indication of pervasive loss of interest or pleasure.\n",
      "\n",
      "Feeling Depressed (Score: 1)\n",
      "----------------------------------------\n",
      "Evidence: feeling tired, worrying about things, get irritated at people a lot\n",
      "Reason: Indicators of negative affect, but not consistently expressed as a pervasive feeling of being down, depressed, or hopeless.\n",
      "\n",
      "Sleep Problems (Score: 3)\n",
      "----------------------------------------\n",
      "Evidence: lately I have been probably about the last few months...I'm sleeping a bit too much...about eight to nine hours and I'm still tired\n",
      "Reason: Clear indication of increased sleep and continued fatigue.\n",
      "\n",
      "Fatigue (Score: 3)\n",
      "----------------------------------------\n",
      "Evidence: feeling tired, I'm still tired\n",
      "Reason: Consistent theme of fatigue throughout the interview.\n",
      "\n",
      "Appetite Changes (Score: N/A)\n",
      "----------------------------------------\n",
      "Evidence: No relevant evidence found\n",
      "Reason: No mention of appetite or weight changes.\n",
      "\n",
      "Negative Self-Perception (Score: N/A)\n",
      "----------------------------------------\n",
      "Evidence: No relevant evidence found\n",
      "Reason: No clear indication of feeling bad about themselves or a sense of failure.\n",
      "\n",
      "Concentration Problems (Score: 1)\n",
      "----------------------------------------\n",
      "Evidence: racing thoughts\n",
      "Reason: Suggests potential concentration difficulties, but no direct statement.\n",
      "\n",
      "Psychomotor Changes (Score: 0)\n",
      "----------------------------------------\n",
      "Evidence: energetic and outgoing\n",
      "Reason: No indication of slowed movement or speech.\n"
     ]
    }
   ],
   "source": [
    "class PHQ8ScoreWithExplanation(BaseModel):\n",
    "    evidence: str  # Direct quotes or references from interview\n",
    "    reason: str  # Brief explanation for the score\n",
    "    score: Union[int, str]  # 0-3 or \"N/A\"\n",
    "\n",
    "class PHQ8ScoresWithExplanations(BaseModel):\n",
    "    nointerest: PHQ8ScoreWithExplanation  # Little interest or pleasure in doing things\n",
    "    depressed: PHQ8ScoreWithExplanation   # Feeling down, depressed, or hopeless\n",
    "    sleep: PHQ8ScoreWithExplanation       # Trouble falling/staying asleep, or sleeping too much\n",
    "    tired: PHQ8ScoreWithExplanation       # Feeling tired or having little energy\n",
    "    appetite: PHQ8ScoreWithExplanation    # Poor appetite or overeating\n",
    "    failure: PHQ8ScoreWithExplanation     # Feeling bad about self or like a failure\n",
    "    concentrating: PHQ8ScoreWithExplanation # Trouble concentrating\n",
    "    moving: PHQ8ScoreWithExplanation      # Moving/speaking slowly or being fidgety/restless\n",
    "\n",
    "system_prompt = \"\"\"You are a AI psychiatrist assessment tool specialized in analyzing interview transcripts to evaluate PHQ-8 (Patient Health Questionnaire-8) scores. The PHQ-8 is a validated depression screening instrument that assesses eight of the nine DSM-IV criteria for depressive disorders over the past 2 weeks.\n",
    "\n",
    "PHQ-8 Scoring System:\n",
    "- 0 = Not at all (0-1 days in the past 2 weeks)\n",
    "- 1 = Several days (2-6 days)\n",
    "- 2 = More than half the days (7-11 days)\n",
    "- 3 = Nearly every day (12-14 days)\n",
    "\n",
    "Key Principles:\n",
    "1. Base all assessments strictly on evidence from the transcript\n",
    "2. When no relevant evidence exists for a symptom, output \"N/A\" rather than assuming absence (score of 0)\n",
    "3. Consider both explicit statements and behavioral indicators in the interview\n",
    "4. Be conservative - only assign scores when there is clear evidence of frequency\n",
    "5. Remember that absence of mention does not necessarily mean absence of symptom\"\"\"\n",
    "\n",
    "quantitative_prompt = f\"\"\"Analyze the following interview transcript and predict PHQ-8 scores for each symptom domain.\n",
    "\n",
    "Interview transcript:\n",
    "<transcript>\n",
    "{patient_transcript}\n",
    "</transcript>\n",
    "\n",
    "Analyze each symptom using the following approach in <thinking> tags:\n",
    "1. Search for direct quotes or behavioral evidence related to each PHQ-8 symptom\n",
    "2. Evaluate the frequency/severity based on available evidence\n",
    "3. If no relevant evidence exists, mark as \"N/A\" rather than assuming absence\n",
    "4. Only assign numeric scores (0-3) when evidence clearly indicates frequency\n",
    "\n",
    "After your analysis, provide your final assessment in <answer> tags as a JSON object.\n",
    "\n",
    "For each symptom, provide:\n",
    "1. \"evidence\": exact quotes from transcript (use \"No relevant evidence found\" if not discussed)\n",
    "2. \"reason\": explanation of scoring decision, including why N/A if applicable\n",
    "3. \"score\": integer 0-3 based on evidence, or \"N/A\" if no relevant evidence\n",
    "\n",
    "Return ONLY a JSON object in <answer> tags with these exact keys:\n",
    "- \"nointerest\": {{evidence, reason, score}} for little interest or pleasure in doing things (anhedonia)\n",
    "- \"depressed\": {{evidence, reason, score}} for feeling down, depressed, or hopeless (depressed mood)\n",
    "- \"sleep\": {{evidence, reason, score}} for trouble falling or staying asleep, or sleeping too much (sleep problems)\n",
    "- \"tired\": {{evidence, reason, score}} for feeling tired or having little energy (fatigue)\n",
    "- \"appetite\": {{evidence, reason, score}} for poor appetite or overeating (appetite/weight changes)\n",
    "- \"failure\": {{evidence, reason, score}} for feeling bad about yourself or that you are a failure (negative self-perception)\n",
    "- \"concentrating\": {{evidence, reason, score}} for trouble concentrating on things like reading or watching TV (concentration problems)\n",
    "- \"moving\": {{evidence, reason, score}} for moving or speaking slowly, or being fidgety/restless (psychomotor changes)\"\"\"\n",
    "\n",
    "# Most deterministic temp, top_k, and top_p\n",
    "response = requests.post(\n",
    "    BASE_URL,\n",
    "    json={\n",
    "        \"model\": model,\n",
    "        \"messages\": [{\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": quantitative_prompt}],\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": 0,\n",
    "            \"top_k\": 1,\n",
    "            \"top_p\": 1.0\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Parse and validate the response\n",
    "try:\n",
    "    response_data = response.json()\n",
    "    content = response_data['message']['content']\n",
    "    \n",
    "    # Extract content from <answer> tags if present\n",
    "    if '<answer>' in content and '</answer>' in content:\n",
    "        content = content.split('<answer>')[1].split('</answer>')[0].strip()\n",
    "    \n",
    "    # Remove markdown code blocks if present\n",
    "    if content.startswith('```json'):\n",
    "        content = content.split('```json')[1].split('```')[0].strip()\n",
    "    elif content.startswith('```'):\n",
    "        content = content.split('```')[1].split('```')[0].strip()\n",
    "    \n",
    "    # Parse the JSON response and validate with Pydantic\n",
    "    scores_dict = json.loads(content)\n",
    "    phq8_scores = PHQ8ScoresWithExplanations(**scores_dict)\n",
    "    \n",
    "    # Extract the 8 PHQ-8 score values\n",
    "    scores_list = [\n",
    "        phq8_scores.nointerest.score,\n",
    "        phq8_scores.depressed.score,\n",
    "        phq8_scores.sleep.score,\n",
    "        phq8_scores.tired.score,\n",
    "        phq8_scores.appetite.score,\n",
    "        phq8_scores.failure.score,\n",
    "        phq8_scores.concentrating.score,\n",
    "        phq8_scores.moving.score\n",
    "    ]\n",
    "    \n",
    "    # Get ground truth values\n",
    "    ground_truth = train_phq8_dataset.iloc[2]\n",
    "\n",
    "    print(\"Comparison of Predicted vs Ground Truth:\")\n",
    "    print(\"Metric\\t\\t\\tPredicted\\tGround Truth\\tDifference\")\n",
    "    print(\"-\" * 65)\n",
    "\n",
    "    differences = []\n",
    "    n_available = 0\n",
    "    num_questions_NA = 0\n",
    "    metrics = ['PHQ8_NoInterest', 'PHQ8_Depressed', 'PHQ8_Sleep', 'PHQ8_Tired', \n",
    "            'PHQ8_Appetite', 'PHQ8_Failure', 'PHQ8_Concentrating', 'PHQ8_Moving']\n",
    "    predicted_values = [phq8_scores.nointerest.score, phq8_scores.depressed.score, phq8_scores.sleep.score, \n",
    "                    phq8_scores.tired.score, phq8_scores.appetite.score, phq8_scores.failure.score,\n",
    "                    phq8_scores.concentrating.score, phq8_scores.moving.score]\n",
    "\n",
    "    for metric, pred_val in zip(metrics, predicted_values):\n",
    "        gt_val = int(ground_truth[metric])\n",
    "        if pred_val == \"N/A\":\n",
    "            diff_str = \"N/A\"\n",
    "            num_questions_NA += 1\n",
    "        else:\n",
    "            diff = abs(pred_val - gt_val)\n",
    "            differences.append(diff)\n",
    "            diff_str = str(diff)\n",
    "            n_available += 1\n",
    "        print(f\"{metric:<23} {str(pred_val):<12} {gt_val:<15} {diff_str}\")\n",
    "\n",
    "    # Calculate metrics\n",
    "    if n_available > 0:\n",
    "        avg_difference = sum(differences) / n_available\n",
    "        accuracy_on_available = 1 - (avg_difference / 3)\n",
    "    else:\n",
    "        avg_difference = float('inf')\n",
    "        accuracy_on_available = 0\n",
    "    \n",
    "    # Accuracy * % available questions\n",
    "    overall_accuracy = accuracy_on_available * (1 - (num_questions_NA / 8))\n",
    "    \n",
    "    print(\"-\" * 65)\n",
    "    if n_available > 0:\n",
    "        print(f\"Average Absolute Difference (on available): {avg_difference:.2f}\")\n",
    "        print(f\"Accuracy on available questions: {accuracy_on_available:.2%}\")\n",
    "    print(f\"Questions marked N/A: {num_questions_NA}/8\")\n",
    "    print(f\"Overall accuracy: {overall_accuracy:.2%}\")\n",
    "    \n",
    "    # Reasoning and evidence section\n",
    "    print(\"\\n\\nDetailed Reasoning for Each Score:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    symptom_names = {\n",
    "        'nointerest': 'Little Interest/Pleasure',\n",
    "        'depressed': 'Feeling Depressed',\n",
    "        'sleep': 'Sleep Problems',\n",
    "        'tired': 'Fatigue',\n",
    "        'appetite': 'Appetite Changes',\n",
    "        'failure': 'Negative Self-Perception',\n",
    "        'concentrating': 'Concentration Problems',\n",
    "        'moving': 'Psychomotor Changes'\n",
    "    }\n",
    "    \n",
    "    for key, symptom_name in symptom_names.items():\n",
    "        score_data = getattr(phq8_scores, key)\n",
    "        print(f\"\\n{symptom_name} (Score: {score_data.score})\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Evidence: {score_data.evidence}\")\n",
    "        print(f\"Reason: {score_data.reason}\")\n",
    "\n",
    "except (json.JSONDecodeError, KeyError, ValueError) as e:\n",
    "    print(f\"Error parsing response: {e}\")\n",
    "    print(\"Raw response:\", response)\n",
    "    print(json.dumps(response.json(), indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a06e17",
   "metadata": {},
   "source": [
    "## Execution Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c600c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "for participant_id in participant_list:\n",
    "\n",
    "    current_transcript = pd.read_csv(fr\"/data/users4/xli/ai-psychiatrist/datasets/daic_woz_dataset/{participant_id}_P/{participant_id}_TRANSCRIPT.csv\", sep=\"\\t\")\n",
    "\n",
    "    # Reformatting transcript data to be a string with speaker name + text\n",
    "    current_patient_transcript = '\\n'.join(current_transcript['speaker'] + ': ' + current_transcript['value'])\n",
    "\n",
    "    #print(patient_transcript + \"\\n\")\n",
    "    #print(train_phq8_dataset.iloc[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe1c069",
   "metadata": {},
   "source": [
    "## Qualitative Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bffa68db",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 14\u001b[0m\n\u001b[1;32m      1\u001b[0m qualitative_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mPlease analyze the following interview transcript and assess the patient\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms mental health status, focusing on signs of depression, from social and biological aspects. \u001b[39m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mPlease provide your assessment in a structured format, including the following sections:\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mpatient_transcript\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Temp, top_k, and top_p set to more deterministic values\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m  \u001b[49m\u001b[43mBASE_URL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m  \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mqualitative_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_k\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.9\u001b[39;49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m  \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(response\u001b[38;5;241m.\u001b[39mjson(), indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[0;32m/data/users2/agreene46/envs/pt2/lib/python3.10/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/users2/agreene46/envs/pt2/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/users2/agreene46/envs/pt2/lib/python3.10/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/data/users2/agreene46/envs/pt2/lib/python3.10/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    700\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/data/users2/agreene46/envs/pt2/lib/python3.10/site-packages/requests/adapters.py:487\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    484\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 487\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/data/users2/agreene46/envs/pt2/lib/python3.10/site-packages/urllib3/connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 714\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/data/users2/agreene46/envs/pt2/lib/python3.10/site-packages/urllib3/connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    461\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    462\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m/data/users2/agreene46/envs/pt2/lib/python3.10/site-packages/urllib3/connectionpool.py:461\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 461\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/data/users2/agreene46/envs/pt2/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/data/users2/agreene46/envs/pt2/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/data/users2/agreene46/envs/pt2/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/data/users2/agreene46/envs/pt2/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "qualitative_prompt = f\"\"\"Please analyze the following interview transcript and assess the patient's mental health status, focusing on signs of depression, from social and biological aspects. \n",
    "\n",
    "Please provide your assessment in a structured format, including the following sections:\n",
    "1. Overall Impression in <overall> tags: A brief summary of the patient's mental health status.\n",
    "2. Social Aspects in <social> tags: Observations related to the patient's interpersonal relationships, family situation, and any relevant social interactions that may influence their mental health.\n",
    "3. Biological Aspects in <biological> tags: Observations related to the patient's physical health, including sleep quality, appetite, physical activity, stress level, and any other biological factors that may influence their mental health.\n",
    "4. Additional Notes in <notes> tags: Any other relevant observations or comments that do not fit into the above categories.\n",
    "5. Potential Risk Factors in <risks> tags: Any identified risk factors for depression or other mental health issues.\n",
    "\n",
    "Here is the interview transcript:\n",
    "{patient_transcript}\n",
    "\"\"\"\n",
    "# Temp, top_k, and top_p set to more deterministic values\n",
    "response = requests.post(\n",
    "  BASE_URL,\n",
    "  json = {\n",
    "    \"model\": model,\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": qualitative_prompt}],\n",
    "    \"stream\": False,\n",
    "    \"options\": {\n",
    "      \"temperature\": 0,\n",
    "      \"top_k\": 20,\n",
    "      \"top_p\": 0.9\n",
    "    }\n",
    "  }\n",
    ")\n",
    "\n",
    "print(json.dumps(response.json(), indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e85875b",
   "metadata": {},
   "source": [
    "## **TESTING ||** Grabbing PHQ-8 related sections from transcript (Using ground truth directly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a2b4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"nointerest_evidence\": [\n",
      "        \"I don't like people too much, so being outdoors and uh I've always enjoyed being outdoors that's how I like being a truck driver I've traveled the world.\",\n",
      "        \"There's not a lot that I like about l_a but um I like hollywood I like the the movie industry um\"\n",
      "    ],\n",
      "    \"depressed_evidence\": [\n",
      "        \"uh I've been diagnosed with uh bipolarism\",\n",
      "        \"I just get a lot of racing thoughts so or I get depressed you know 'cause I or I worry about things that you know that really I have no control over\"\n",
      "    ],\n",
      "    \"sleep_evidence\": [\n",
      "        \"It's been hard lately it's been probably hard for the last uh going on a year um you know I uh depending on my thought process at the time I like I said I've been looking for work quite a bit um so just wondering why you know I don't get called I I just have my I have racing thoughts\",\n",
      "        \"lately I have been probably about the last few months\"\n",
      "    ],\n",
      "    \"tired_evidence\": [\n",
      "        \"lately I've been sleeping a bit too much uh at least for me because I'm so used to just sleeping four to five hours a a a night but now it's changed to about eight to nine hours and I'm still tired\",\n",
      "        \"if I don't sleep well sometimes then I just dwell back on the same things that have been bothering me\"\n",
      "    ],\n",
      "    \"appetite_evidence\": [\n",
      "        \"I don't have health insurance there's a lot of things that you know I'd like to do but I can't you know um money situation's not that great right now\"\n",
      "    ],\n",
      "    \"failure_evidence\": [\n",
      "        \"I've been on probably every imaginable pill that there is for that and um you know some of them have been too strong or some of them not strong enough\",\n",
      "        \"I just get a lot of racing thoughts so or I get depressed you know 'cause I or I worry about things that you know that really I have no control over\"\n",
      "    ],\n",
      "    \"concentrating_evidence\": [],\n",
      "    \"moving_evidence\": [],\n",
      "    \"scores\": {\n",
      "        \"nointerest\": 0,\n",
      "        \"depressed\": 1,\n",
      "        \"sleep\": 1,\n",
      "        \"tired\": 2,\n",
      "        \"appetite\": 2,\n",
      "        \"failure\": 1,\n",
      "        \"concentrating\": 0,\n",
      "        \"moving\": 0\n",
      "    }\n",
      "}\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "class PHQ8Evidence(BaseModel):\n",
    "    nointerest_evidence: List[str]\n",
    "    depressed_evidence: List[str]\n",
    "    sleep_evidence: List[str]\n",
    "    tired_evidence: List[str]\n",
    "    appetite_evidence: List[str]\n",
    "    failure_evidence: List[str]\n",
    "    concentrating_evidence: List[str]\n",
    "    moving_evidence: List[str]\n",
    "\n",
    "evidence_extraction_prompt = f\"\"\"Analyze the following therapy transcript and extract specific text chunks that provide evidence for each PHQ-8 score. For each PHQ-8 domain, find 1-3 relevant quotes from the transcript that best support the given score.\n",
    "\n",
    "PHQ-8 scoring reference:\n",
    "- 0 = not at all (0-1 days)\n",
    "- 1 = several days (2-6 days) \n",
    "- 2 = more than half the days (7-11 days)\n",
    "- 3 = nearly every day (12-14 days)\n",
    "\n",
    "Given PHQ-8 scores: {train_phq8_dataset.iloc[2]}\n",
    "\n",
    "For each domain below, extract direct quotes from the transcript that justify the given score. If the score is 0, find evidence showing the absence or minimal presence of that symptom. If the score is higher, find evidence showing the frequency/severity indicated by that score.\n",
    "\n",
    "PHQ-8 domains:\n",
    "- nointerest: little interest or pleasure in activities\n",
    "- depressed: feeling down, depressed, or hopeless\n",
    "- sleep: sleep problems (trouble falling/staying asleep or sleeping too much)\n",
    "- tired: feeling tired or having little energy\n",
    "- appetite: appetite changes (poor appetite or overeating)\n",
    "- failure: negative self-perception or feeling like a failure\n",
    "- concentrating: trouble concentrating on tasks\n",
    "- moving: psychomotor changes (moving/speaking slowly or restlessness)\n",
    "\n",
    "Return a JSON object with arrays of relevant transcript quotes for each domain. Each quote should be a direct excerpt from the transcript that supports the given score.\n",
    "\n",
    "Therapy transcript:\n",
    "{patient_transcript}\n",
    "\n",
    "Respond with valid JSON matching this structure:\n",
    "{{\n",
    "    \"nointerest_evidence\": [\"quote1\", \"quote2\"],\n",
    "    \"depressed_evidence\": [\"quote1\", \"quote2\"],\n",
    "    \"sleep_evidence\": [\"quote1\", \"quote2\"],\n",
    "    \"tired_evidence\": [\"quote1\", \"quote2\"],\n",
    "    \"appetite_evidence\": [\"quote1\", \"quote2\"],\n",
    "    \"failure_evidence\": [\"quote1\", \"quote2\"],\n",
    "    \"concentrating_evidence\": [\"quote1\", \"quote2\"],\n",
    "    \"moving_evidence\": [\"quote1\", \"quote2\"]\n",
    "}}\n",
    "\n",
    "Important: Extract UNIQUE quotes only - do not repeat the same quote multiple times. Each quote should be different and provide distinct evidence.\n",
    "\"\"\"\n",
    "\n",
    "response = requests.post(\n",
    "    BASE_URL,\n",
    "    json={\n",
    "        \"model\": model,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": evidence_extraction_prompt}],\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": 0.1,\n",
    "            \"top_k\": 10,\n",
    "            \"top_p\": 0.8\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Printing\n",
    "response_data = response.json()\n",
    "content = response_data['message']['content']\n",
    "content = content.strip('```json\\n').strip('\\n```')\n",
    "\n",
    "evidence_dict = json.loads(content)\n",
    "\n",
    "# Add scores to the output\n",
    "scores = train_phq8_dataset.iloc[2]\n",
    "evidence_dict['scores'] = {\n",
    "    'nointerest': int(scores['PHQ8_NoInterest']),\n",
    "    'depressed': int(scores['PHQ8_Depressed']),\n",
    "    'sleep': int(scores['PHQ8_Sleep']),\n",
    "    'tired': int(scores['PHQ8_Tired']),\n",
    "    'appetite': int(scores['PHQ8_Appetite']),\n",
    "    'failure': int(scores['PHQ8_Failure']),\n",
    "    'concentrating': int(scores['PHQ8_Concentrating']),\n",
    "    'moving': int(scores['PHQ8_Moving'])\n",
    "}\n",
    "\n",
    "# Remove duplicate quotes in each evidence list\n",
    "for key in evidence_dict:\n",
    "    if isinstance(evidence_dict[key], list):\n",
    "        evidence_dict[key] = list(dict.fromkeys(evidence_dict[key]))\n",
    "\n",
    "formatted_output = json.dumps(evidence_dict, indent=4)\n",
    "print(\"!! THIS DOES NOT PREDICT SCORES IT JUST PULLS RELAVENT EVIDENCE FROM THE TRANSCRIPT USING LLM'S !!\\n\\n\")\n",
    "print(formatted_output)\n",
    "print(type(formatted_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2a3418",
   "metadata": {},
   "source": [
    "### Original ollama example script (for reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ada34e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"model\": \"qwq:latest\",\n",
      "  \"created_at\": \"2025-07-15T22:46:58.150903388Z\",\n",
      "  \"message\": {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"<think>\\nOkay, the user is asking, \\\"What is the capital of France?\\\" Let me think about how to approach this.\\n\\nFirst, I need to confirm the correct answer. The capital of France is Paris. That's a well-known fact, but I should make sure there hasn't been any recent changes, which is unlikely. \\n\\nNext, I should consider why the user is asking this. It might be a straightforward question for someone learning basic geography. Alternatively, they could be testing the system's knowledge. Either way, the answer needs to be clear and accurate.\\n\\nI should also think about providing a bit more context. Maybe mention that Paris is not only the capital but also the most populous city in France. Including some landmarks like the Eiffel Tower or the Louvre could add value. But wait, the user didn't ask for extra details, so maybe keep it concise unless they ask for more.\\n\\nAnother point: sometimes people confuse France with other countries. For example, someone might mix up France and Italy, whose capital is Rome. So reinforcing that France's capital is indeed Paris helps avoid confusion.\\n\\nIs there any chance the question is a trick question? Like, maybe considering overseas territories? But no, the capital cities of countries are typically their main metropolitan cities. France's capital is definitely Paris.\\n\\nAlso, considering the user's possible follow-up questions, but since the current query is straightforward, stick to the answer. Make sure the response is in the user's language, which is English here. Avoid any markdown formatting as per the instructions. Just a clear, direct answer with a brief explanation.\\n\\nWait, the user might be a student needing this for homework, or someone planning a trip. Either way, accuracy is key. Let me double-check a reliable source in my database. Yes, all sources confirm Paris as the capital. Alright, time to compose the response.\\n</think>\\n\\nThe capital of France is **Paris**. It is not only the political and cultural heart of the country but also one of the most famous cities globally, known for landmarks like the Eiffel Tower, the Louvre Museum, and its iconic fashion and cuisine.\"\n",
      "  },\n",
      "  \"done_reason\": \"stop\",\n",
      "  \"done\": true,\n",
      "  \"total_duration\": 109427941229,\n",
      "  \"load_duration\": 97772517579,\n",
      "  \"prompt_eval_count\": 15,\n",
      "  \"prompt_eval_duration\": 858250578,\n",
      "  \"eval_count\": 435,\n",
      "  \"eval_duration\": 10796520205\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Available models:\n",
    "- gemma3-optimized:27b\n",
    "- gemma3_optimized:8bit\n",
    "- gemma3:27b-it-qat\n",
    "- gemma3:27b\n",
    "- phi4-optimized:latest\n",
    "- phi4:latest\n",
    "- phi4-reasoning:plus\n",
    "- qwen3_optimized:latest\n",
    "- qwen3:32b\n",
    "- llama3.3:latest\n",
    "- llama4:scout\n",
    "- mistral3.1-optimized:latest\n",
    "- mistral-small3.1:latest\n",
    "- qwq:latest\n",
    "\n",
    "Notes:\n",
    "1. The models marked as \"optimized\" are configured to use multiple GPUs for faster inference.\n",
    "2. The llama4:maverick model is not available due to its size.\n",
    "\"\"\"\n",
    "\n",
    "OLLAMA_NODE = \"arctrddgxa002\" # TODO: Change this variable to the node where Ollama is running\n",
    "BASE_URL = f\"http://{OLLAMA_NODE}:11434/api/chat\"\n",
    "\n",
    "model = \"qwq:latest\" # TODO: Change this variable to the model you want to use\n",
    "message = \"What is the capital of France?\" # TODO: Change this variable to the message you want to ask the model\n",
    "\n",
    "response = requests.post(\n",
    "  BASE_URL,\n",
    "  json = {\n",
    "    \"model\": model,\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": message}],\n",
    "    \"stream\": False\n",
    "  }\n",
    ")\n",
    "\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
