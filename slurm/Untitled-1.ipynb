{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb7bc435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV file...\n",
      "Loaded 142 participants\n",
      "No existing results found, starting fresh\n",
      "\n",
      "--- Processing 1/142: 303 ---\n",
      "Looking for transcript at: /data/users4/xli/ai-psychiatrist/datasets/daic_woz_dataset/303_P/303_TRANSCRIPT.csv\n",
      "Successfully loaded transcript for 303 (191 entries)\n",
      "  Getting coherence response...\n",
      "  Coherence score: 5\n",
      "  Getting completeness response...\n",
      "  Completeness score: 1\n",
      "  Getting specificity response...\n",
      "  Specificity score: 4\n",
      "  Getting accuracy response...\n",
      "  Accuracy score: 5\n",
      "  Getting collective explanation...\n",
      "  Collective: ## Overall Quality Assessment: Good, with Minor Ar...\n",
      "Completed participant 303 in 142.8s (1 total completed)\n",
      "Saved progress: 1 results to /data/users2/nblair7/analysis_results/eval_results_newtest.csv\n",
      "\n",
      "--- Processing 2/142: 304 ---\n",
      "Looking for transcript at: /data/users4/xli/ai-psychiatrist/datasets/daic_woz_dataset/304_P/304_TRANSCRIPT.csv\n",
      "Successfully loaded transcript for 304 (204 entries)\n",
      "  Getting coherence response...\n",
      "  Coherence score: 5\n",
      "  Getting completeness response...\n",
      "  Completeness score: 5\n",
      "  Getting specificity response...\n",
      "  Specificity score: 4\n",
      "  Getting accuracy response...\n",
      "  Accuracy score: 5\n",
      "  Getting collective explanation...\n",
      "  Collective: ## Overall Quality Assessment\n",
      "\n",
      "This qualitative as...\n",
      "Completed participant 304 in 137.9s (2 total completed)\n",
      "\n",
      "--- Processing 3/142: 305 ---\n",
      "Looking for transcript at: /data/users4/xli/ai-psychiatrist/datasets/daic_woz_dataset/305_P/305_TRANSCRIPT.csv\n",
      "Successfully loaded transcript for 305 (405 entries)\n",
      "  Getting coherence response...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 227\u001b[39m\n\u001b[32m    225\u001b[39m \u001b[38;5;66;03m# coherence\u001b[39;00m\n\u001b[32m    226\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m  Getting coherence response...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m coherence_response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBASE_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoherence_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m coherence_response.status_code == \u001b[32m200\u001b[39m:\n\u001b[32m    229\u001b[39m     coherence_content = coherence_response.json()[\u001b[33m'\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/users2/nblair7/envs/aipsy/lib/python3.11/site-packages/requests/api.py:115\u001b[39m, in \u001b[36mpost\u001b[39m\u001b[34m(url, data, json, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(url, data=\u001b[38;5;28;01mNone\u001b[39;00m, json=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    104\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    112\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/users2/nblair7/envs/aipsy/lib/python3.11/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/users2/nblair7/envs/aipsy/lib/python3.11/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/users2/nblair7/envs/aipsy/lib/python3.11/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/users2/nblair7/envs/aipsy/lib/python3.11/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/users2/nblair7/envs/aipsy/lib/python3.11/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/users2/nblair7/envs/aipsy/lib/python3.11/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/users2/nblair7/envs/aipsy/lib/python3.11/site-packages/urllib3/connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    562\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    568\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/users2/nblair7/envs/aipsy/lib/python3.11/http/client.py:1395\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1393\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1394\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1395\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1396\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1397\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/users2/nblair7/envs/aipsy/lib/python3.11/http/client.py:325\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    327\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/users2/nblair7/envs/aipsy/lib/python3.11/http/client.py:286\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.fp.readline(_MAXLINE + \u001b[32m1\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    288\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/users2/nblair7/envs/aipsy/lib/python3.11/socket.py:718\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    716\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m718\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    720\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "from requests.exceptions import Timeout, RequestException\n",
    "\n",
    "def parse_score_and_explanation(response_text):\n",
    "    \"\"\"Extract score and explanation from model response\"\"\"\n",
    "    score_patterns = [\n",
    "        r'score[:\\s]*(\\d+)',\n",
    "        r'(\\d+)[/\\s]*(?:out of\\s*)?5',\n",
    "        r'(\\d+)[/\\s]*5',\n",
    "        r'rating[:\\s]*(\\d+)',\n",
    "        r'^(\\d+)',  # Number at start of line\n",
    "    ]\n",
    "    \n",
    "    score = None\n",
    "    for pattern in score_patterns:\n",
    "        match = re.search(pattern, response_text, re.IGNORECASE | re.MULTILINE)\n",
    "        if match:\n",
    "            potential_score = int(match.group(1))\n",
    "            if 1 <= potential_score <= 5:\n",
    "                score = potential_score\n",
    "                break\n",
    "    \n",
    "    return score, response_text.strip()\n",
    "\n",
    "def load_transcript(participant_id):\n",
    "    \"\"\"Load transcript for a given participant ID\"\"\"\n",
    "    id_transcript = os.path.join(\"/data/users4/xli/ai-psychiatrist/datasets/daic_woz_dataset/\", f\"{participant_id}_P\", f\"{participant_id}_TRANSCRIPT.csv\")\n",
    "    print(f\"Looking for transcript at: {id_transcript}\")\n",
    "    \n",
    "    if not os.path.exists(id_transcript):\n",
    "        print(f\"Transcript not found for {participant_id}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        transcript_df = pd.read_csv(id_transcript)\n",
    "        # Convert transcript to readable format\n",
    "        transcript_text = \"\"\n",
    "        for _, row in transcript_df.iterrows():\n",
    "            speaker = row.get('speaker', 'Unknown')\n",
    "            text = row.get('value', row.get('text', ''))\n",
    "            transcript_text += f\"{speaker}: {text}\\n\"\n",
    "        \n",
    "        print(f\"Successfully loaded transcript for {participant_id} ({len(transcript_df)} entries)\")\n",
    "        return transcript_text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading transcript for {participant_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Configuration\n",
    "OLLAMA_NODE = \"arctrddgxa002\" # TODO: Change this variable to the node where Ollama is running\n",
    "BASE_URL = f\"http://{OLLAMA_NODE}:11434/api/chat\"\n",
    "model = \"gemma3-optimized:27b\" # TODO: Change this variable to the model you want to use\n",
    "\n",
    "# File paths\n",
    "input_csv_path = \"/data/users2/nblair7/analysis_results/qual_resultsfin.csv\"\n",
    "output_csv_path = \"/data/users2/nblair7/analysis_results/eval_results_newtest.csv\" \n",
    "\n",
    "# Load the CSV file\n",
    "print(\"Loading CSV file...\")\n",
    "df = pd.read_csv(input_csv_path)\n",
    "print(f\"Loaded {len(df)} participants\")\n",
    "\n",
    "results = []\n",
    "failed_evaluations = []\n",
    "processed_count = 0\n",
    "skipped_count = 0\n",
    "\n",
    "import os\n",
    "if os.path.exists(output_csv_path):\n",
    "    print(f\"Found existing results file: {output_csv_path}\")\n",
    "    existing_results = pd.read_csv(output_csv_path)\n",
    "    completed_subjects = set(existing_results['participant_id'].tolist())\n",
    "    print(f\"Already completed {len(completed_subjects)} subjects\")\n",
    "    \n",
    "    df = df[~df['participant_id'].isin(completed_subjects)]\n",
    "    print(f\"Remaining subjects to process: {len(df)}\")\n",
    "    \n",
    "    results = existing_results.to_dict('records')\n",
    "else:\n",
    "    print(\"No existing results found, starting fresh\")\n",
    "    completed_subjects = set()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    participant_id = row['participant_id']\n",
    "    qualitative_assessment = row['qualitative_assessment']\n",
    "    \n",
    "    print(f\"\\n--- Processing {index + 1}/{len(df)}: {participant_id} ---\")\n",
    "    \n",
    "    # Load transcript for this participant\n",
    "    transcript = load_transcript(participant_id)\n",
    "    if transcript is None:\n",
    "        print(f\"Skipping {participant_id} - no transcript found\")\n",
    "        skipped_count += 1\n",
    "        continue\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    #scoring criteria\n",
    "    score = \"You are an expert psychiatrist evaluating qualitative assessments of mental health conditions. Evaluate on a score of 1-5 for the metric based on the following criteria: A score of 5 is 0 mistakes. A score of 4 is 1-2 mistakes. A score of 3 is 3-4 mistakes. A score of 2 is 5-6 mistakes. A score of 1 is 7 or more mistakes\"\n",
    "    \n",
    "    # metric prompts\n",
    "    coherence_prompt = f\"\"\"Evaluate the following qualitative assessment output for COHERENCE only. Compare qualitative_assessment to the provided transcript.\n",
    "Score from 1-5 based on the following criteria: {score}\n",
    "\n",
    "Coherence (1–5): Is the response logically consistent? Mistakes are logically inconsistent statements or contradictions within the assessment.\n",
    "\n",
    "Format your response as:\n",
    "Score: [your score]\n",
    "Explanation: [explanation]\n",
    "\n",
    "---\n",
    "Here is the transcript: \n",
    "{transcript}\n",
    "\n",
    "Here is the assessment based on the transcript: \n",
    "{qualitative_assessment}\n",
    "---\"\"\"\n",
    "\n",
    "    completeness_prompt = f\"\"\"Evaluate the following qualitative assessment output for COMPLETENESS only. Compare qualitative_assessment to the provided transcript.\n",
    "\n",
    "Score from 1-5 based on the following criteria: {score}\n",
    "\n",
    "Completeness (1–5): Does the assessment cover all relevant symptoms, severities, duration/frequency? Mistakes have missed PHQ-8 symptoms, or duration/frequency details.\n",
    "\n",
    "Format your response as:\n",
    "Score: [your score]\n",
    "Explanation: [explanation]\n",
    "\n",
    "Here is the transcript: \n",
    "{transcript}\n",
    "\n",
    "Here is the assessment based on the transcript: \n",
    "{qualitative_assessment}\n",
    "---\"\"\"\n",
    "\n",
    "    specificity_prompt = f\"\"\"Evaluate the following qualitative assessment output for SPECIFICITY only. Compare qualitative_assessment to the provided transcript.\n",
    "\n",
    "Score from 1-5 based on the following criteria: {score}\n",
    "\n",
    "specificity (1–5): Is the assessment specific? Mistakes include using vague/generic statements like 'the patient seems depressed'.\n",
    "\n",
    "Format your response as:\n",
    "Score: [your score]\n",
    "Explanation: [explanation]\n",
    "\n",
    "\n",
    "---\n",
    "Here is the transcript: \n",
    "{transcript}\n",
    "\n",
    "Here is the assessment based on the transcript: \n",
    "{qualitative_assessment}\n",
    "---\"\"\"\n",
    "\n",
    "    accuracy_prompt = f\"\"\"Evaluate the following qualitative assessment output for ACCURACY only. Compare qualitative_assessment to the provided transcript.\n",
    "\n",
    "Score from 1-5 based on the following criteria: {score}\n",
    "\n",
    "Accuracy (1–5): Are the signs/symptoms aligned with DSM-5 or PHQ-8? Mistakes are incorrect symptoms or incorrect duration/frequecy. \n",
    "\n",
    "Format your response as:\n",
    "Score: [your score]\n",
    "Explanation: [explanation]\n",
    "\n",
    "\n",
    "---\n",
    "Here is the transcript: \n",
    "{transcript}\n",
    "\n",
    "Here is the assessment based on the transcript: \n",
    "{qualitative_assessment}\n",
    "---\"\"\"\n",
    "\n",
    "    collective_prompt = f\"\"\"Provide a brief collective explanation/summary of the overall quality of this qualitative assessment, considering all aspects: coherence, completeness, specificity, and accuracy together. Explain scoring and provide evidence of any mistakes made..\n",
    "\n",
    "---\n",
    "{qualitative_assessment}\n",
    "---\"\"\"\n",
    "\n",
    "    # requests for each metric\n",
    "    coherence_request = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": coherence_prompt}],\n",
    "        \"stream\": False,\n",
    "        \"options\": {\"temperature\": 0, \"top_k\": 20, \"top_p\": 0.9}\n",
    "    }\n",
    "    \n",
    "    completeness_request = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": completeness_prompt}],\n",
    "        \"stream\": False,\n",
    "        \"options\": {\"temperature\": 0, \"top_k\": 20, \"top_p\": 0.9}\n",
    "    }\n",
    "    \n",
    "    specificity_request = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": specificity_prompt}],\n",
    "        \"stream\": False,\n",
    "        \"options\": {\"temperature\": 0, \"top_k\": 20, \"top_p\": 0.9}\n",
    "    }\n",
    "    \n",
    "    accuracy_request = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": accuracy_prompt}],\n",
    "        \"stream\": False,\n",
    "        \"options\": {\"temperature\": 0, \"top_k\": 20, \"top_p\": 0.9}\n",
    "    }\n",
    "    \n",
    "    collective_request = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": collective_prompt}],\n",
    "        \"stream\": False,\n",
    "        \"options\": {\"temperature\": 0, \"top_k\": 20, \"top_p\": 0.9}\n",
    "    }\n",
    "    \n",
    "    timeout = 300  \n",
    "    \n",
    "    try:\n",
    "        result = {'participant_id': participant_id}\n",
    "        \n",
    "        # coherence\n",
    "        print(\"  Getting coherence response...\")\n",
    "        coherence_response = requests.post(BASE_URL, json=coherence_request, timeout=timeout-10)\n",
    "        if coherence_response.status_code == 200:\n",
    "            coherence_content = coherence_response.json()['message']['content']\n",
    "            coherence_score, _ = parse_score_and_explanation(coherence_content)\n",
    "            result['coherence'] = coherence_score\n",
    "            result['coherence_explanation'] = coherence_content  # Store full response\n",
    "            print(f\"  Coherence score: {coherence_score}\")\n",
    "        else:\n",
    "            result['coherence'] = None\n",
    "            result['coherence_explanation'] = f\"API Error: {coherence_response.status_code}\"\n",
    "        \n",
    "        time.sleep(2)\n",
    "        \n",
    "        # completeness\n",
    "        print(\"  Getting completeness response...\")\n",
    "        completeness_response = requests.post(BASE_URL, json=completeness_request, timeout=timeout-10)\n",
    "        if completeness_response.status_code == 200:\n",
    "            completeness_content = completeness_response.json()['message']['content']\n",
    "            completeness_score, _ = parse_score_and_explanation(completeness_content)\n",
    "            result['completeness'] = completeness_score\n",
    "            result['completeness_explanation'] = completeness_content  # Store full response\n",
    "            print(f\"  Completeness score: {completeness_score}\")\n",
    "        else:\n",
    "            result['completeness'] = None\n",
    "            result['completeness_explanation'] = f\"API Error: {completeness_response.status_code}\"\n",
    "        \n",
    "        time.sleep(2)\n",
    "        \n",
    "        # specificity\n",
    "        print(\"  Getting specificity response...\")\n",
    "        specificity_response = requests.post(BASE_URL, json=specificity_request, timeout=timeout-10)\n",
    "        if specificity_response.status_code == 200:\n",
    "            specificity_content = specificity_response.json()['message']['content']\n",
    "            specificity_score, _ = parse_score_and_explanation(specificity_content)\n",
    "            result['specificity'] = specificity_score\n",
    "            result['specificity_explanation'] = specificity_content  # Store full response\n",
    "            print(f\"  Specificity score: {specificity_score}\")\n",
    "        else:\n",
    "            result['specificity'] = None\n",
    "            result['specificity_explanation'] = f\"API Error: {specificity_response.status_code}\"\n",
    "        \n",
    "        time.sleep(2)\n",
    "        \n",
    "        # accuaracy\n",
    "        print(\"  Getting accuracy response...\")\n",
    "        accuracy_response = requests.post(BASE_URL, json=accuracy_request, timeout=timeout-10)\n",
    "        if accuracy_response.status_code == 200:\n",
    "            accuracy_content = accuracy_response.json()['message']['content']\n",
    "            accuracy_score, _ = parse_score_and_explanation(accuracy_content)\n",
    "            result['accuracy'] = accuracy_score\n",
    "            result['accuracy_explanation'] = accuracy_content  # Store full response\n",
    "            print(f\"  Accuracy score: {accuracy_score}\")\n",
    "        else:\n",
    "            result['accuracy'] = None\n",
    "            result['accuracy_explanation'] = f\"API Error: {accuracy_response.status_code}\"\n",
    "        \n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Collective explanation\n",
    "        print(\"  Getting collective explanation...\")\n",
    "        collective_response = requests.post(BASE_URL, json=collective_request, timeout=timeout-10)\n",
    "        if collective_response.status_code == 200:\n",
    "            result['collective_explanation'] = collective_response.json()['message']['content']\n",
    "            print(f\"  Collective: {result['collective_explanation'][:50]}...\")\n",
    "        else:\n",
    "            result['collective_explanation'] = 'API request failed'\n",
    "        \n",
    "        results.append(result)\n",
    "        processed_count += 1\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Completed participant {participant_id} in {elapsed_time:.1f}s ({processed_count} total completed)\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing participant {participant_id}: {e}\")\n",
    "        result = {\n",
    "            'participant_id': participant_id,\n",
    "            'coherence': None,\n",
    "            'completeness': None,\n",
    "            'specificity': None,\n",
    "            'accuracy': None,\n",
    "            'coherence_explanation': f\"Error: {e}\",\n",
    "            'completeness_explanation': f\"Error: {e}\",\n",
    "            'specificity_explanation': f\"Error: {e}\",\n",
    "            'accuracy_explanation': f\"Error: {e}\",\n",
    "            'collective_explanation': f\"Error: {e}\",\n",
    "        }\n",
    "        results.append(result)\n",
    "        failed_evaluations.append(participant_id)\n",
    "    \n",
    "    # Save progress every 10 participants\n",
    "    if len(results) % 10 == 0 or len(results) == 1:\n",
    "        resultsdf = pd.DataFrame(results)\n",
    "        resultsdf.to_csv(output_csv_path, index=False)\n",
    "        print(f\"Saved progress: {len(results)} results to {output_csv_path}\")\n",
    "    \n",
    "    time.sleep(1)\n",
    "\n",
    "# Final summary\n",
    "print(f\"\\n=== PROCESSING SUMMARY ===\")\n",
    "print(f\"Total subjects in input: {len(df) + len(completed_subjects)}\")\n",
    "print(f\"Previously completed: {len(completed_subjects)}\")\n",
    "print(f\"Attempted this run: {len(df)}\")\n",
    "print(f\"Skipped (no transcript): {skipped_count}\")\n",
    "print(f\"Successfully processed: {processed_count}\")\n",
    "print(f\"Failed: {len(failed_evaluations)}\")\n",
    "print(f\"Total results collected: {len(results)}\")\n",
    "\n",
    "if failed_evaluations:\n",
    "    print(f\"Failed participant IDs: {failed_evaluations}\")\n",
    "\n",
    "# Save final results\n",
    "if results:\n",
    "    resultsdf = pd.DataFrame(results)\n",
    "    resultsdf.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Final save completed: {output_csv_path}\")\n",
    "    print(f\"\\nCSV columns created:\")\n",
    "    print(f\"- participant_id\")\n",
    "    print(f\"- coherence / coherence_explanation\")\n",
    "    print(f\"- completeness / completeness_explanation\") \n",
    "    print(f\"- specificity / specificity_explanation\")\n",
    "    print(f\"- accuracy / accuracy_explanation\")\n",
    "    print(f\"- collective_explanation\")\n",
    "else:\n",
    "    print(\"No results to save!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aipsy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
